import streamlit as st
import pdfplumber
import re
import warnings
import logging
from io import BytesIO

# --- –ù–ê–°–¢–†–û–ô–ö–ò –õ–û–ì–ò–†–û–í–ê–ù–ò–Ø (–ß–∏—Å—Ç–∞—è –∫–æ–Ω—Å–æ–ª—å) ---
logging.getLogger("pdfminer").setLevel(logging.ERROR)
warnings.filterwarnings("ignore", category=UserWarning)
warnings.filterwarnings("ignore", category=FutureWarning)

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –°–¢–†–ê–ù–ò–¶–´ ---
st.set_page_config(page_title="–ü–∞—Ä—Å–µ—Ä –†–µ—î—Å—Ç—Ä—É –ù–µ—Ä—É—Ö–æ–º–æ—Å—Ç—ñ", layout="wide")

# --- CSS –°–¢–ò–õ–ò ---
st.markdown("""
<style>
    .reportview-container {
        font-family: 'Times New Roman', Times, serif;
    }
    .result-container {
        font-family: 'Times New Roman', Times, serif;
        font-size: 19px; 
        line-height: 1.6;
        background-color: #f5f5f5;
        border: 1px solid #cccccc;
        border-radius: 5px;
        padding: 20px;
        color: #000000;
        /* white-space: pre-wrap; –£–ë–†–ê–ù–û, —Ç–∞–∫ –∫–∞–∫ –∏—Å–ø–æ–ª—å–∑—É–µ–º <br> –¥–ª—è –ø–µ—Ä–µ–Ω–æ—Å–æ–≤ */
    }
    .result-container strong {
        font-weight: bold;
        color: #000000;
    }
</style>
""", unsafe_allow_html=True)

# --- –§–£–ù–ö–¶–ò–ò –ü–ê–†–°–ò–ù–ì–ê ---

def clean_text(text):
    if not text:
        return ""
    return re.sub(r'\s+', ' ', text).strip()

def extract_field(text, field_name, stop_at=None):
    base_pattern = re.escape(field_name) + r'\s*:\s*'
    if stop_at:
        stop_pattern = r'(.*?)(?=' + re.escape(stop_at) + r'|\Z)'
    else:
        stop_pattern = r'(.*?)(?=\s+[–ê-–Ø–Ü–á–Ñ][–ê-–Ø–Ü–á–Ñ–∞-—è—ñ—ó—î‚Äô\s]+:|–í–Ü–î–û–ú–û–°–¢–Ü|–ê–∫—Ç—É–∞–ª—å–Ω–∞|–î–∞—Ç–∞|\Z)'
    
    full_pattern = base_pattern + stop_pattern
    match = re.search(full_pattern, text, re.IGNORECASE | re.DOTALL)
    if match:
        return clean_text(match.group(1))
    return None

def parse_pdf_file(uploaded_file):
    try:
        full_text = ""
        with pdfplumber.open(uploaded_file) as pdf:
            for page in pdf.pages:
                text = page.extract_text()
                if text:
                    full_text += text + "\n"
        
        full_text = clean_text(full_text)
        results = []

        if not full_text:
            return "–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞."

        blocks = full_text.split("–ó –î–ï–†–ñ–ê–í–ù–û–ì–û –†–ï–Ñ–°–¢–†–£ –†–ï–ß–û–í–ò–• –ü–†–ê–í")

        for block in blocks:
            if not block or len(block) < 50:
                continue

            # --- –ë–ª–æ–∫ "–í–Ü–î–û–ú–û–°–¢–Ü –ü–†–û –û–ë‚Äô–Ñ–ö–¢ –ù–ï–†–£–•–û–ú–û–ì–û –ú–ê–ô–ù–ê" ---
            legacy_pattern = r"–í–Ü–î–û–ú–û–°–¢–Ü –ü–†–û –û–ë‚Äô–Ñ–ö–¢ –ù–ï–†–£–•–û–ú–û–ì–û –ú–ê–ô–ù–ê"
            legacy_match = re.search(legacy_pattern, block)

            if legacy_match:
                legacy_start = legacy_match.end()
                next_header_match = re.search(r"–í–Ü–î–û–ú–û–°–¢–Ü –ü–†–û –ü–†–ê–í–ê|–í–Ü–î–û–ú–û–°–¢–Ü –ó –Ñ–î–ò–ù–û–ì–û", block[legacy_start:])
                legacy_end = len(block) if not next_header_match else legacy_start + next_header_match.start()
                legacy_text = block[legacy_start:legacy_end]
                
                p_type = extract_field(legacy_text, "–¢–∏–ø –º–∞–π–Ω–∞", stop_at="–ê–¥—Ä–µ—Å–∞ –Ω–µ—Ä—É—Ö–æ–º–æ–≥–æ –º–∞–π–Ω–∞:")
                p_address = extract_field(legacy_text, "–ê–¥—Ä–µ—Å–∞ –Ω–µ—Ä—É—Ö–æ–º–æ–≥–æ –º–∞–π–Ω–∞", stop_at="–ó–∞–≥–∞–ª—å–Ω–∞ –ø–ª–æ—â–∞ (–∫–≤.–º):")
                p_area = extract_field(legacy_text, "–ó–∞–≥–∞–ª—å–Ω–∞ –ø–ª–æ—â–∞ (–∫–≤.–º)", stop_at="–ù–æ–º–µ—Ä –∑–∞–ø–∏—Å—É:")
                
                if p_type or p_address or p_area:
                    results.append({
                        "–¢–∏–ø –º–∞–π–Ω–∞": p_type,
                        "–ê–¥—Ä–µ—Å–∞ –Ω–µ—Ä—É—Ö–æ–º–æ–≥–æ –º–∞–π–Ω–∞": p_address,
                        "–ó–∞–≥–∞–ª—å–Ω–∞ –ø–ª–æ—â–∞ (–∫–≤.–º)": p_area
                    })

            # --- –ë–ª–æ–∫ –û–±—Ä–µ–º–µ–Ω–µ–Ω–∏–π ---
            enc_pattern = r"–ê–∫—Ç—É–∞–ª—å–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –¥–µ—Ä–∂–∞–≤–Ω—É —Ä–µ—î—Å—Ç—Ä–∞—Ü—ñ—é –æ–±—Ç—è–∂–µ–Ω—å"
            enc_match = re.search(enc_pattern, block)

            if enc_match:
                enc_start = enc_match.end()
                next_section_match = re.search(r"(–ê–∫—Ç—É–∞–ª—å–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –æ–±‚Äô—î–∫—Ç|–í–Ü–î–û–ú–û–°–¢–Ü –ó –†–ï–Ñ–°–¢–†–£)", block[enc_start:])
                
                enc_end = len(block)
                if next_section_match:
                    enc_end = enc_start + next_section_match.start()
                
                enc_text = block[enc_start:enc_end]
                
                enc_basis = extract_field(enc_text, "–ü—ñ–¥—Å—Ç–∞–≤–∞ –≤–Ω–µ—Å–µ–Ω–Ω—è –∑–∞–ø–∏—Å—É", stop_at="–í–∏–¥ –æ–±—Ç—è–∂–µ–Ω–Ω—è:")
                enc_type = extract_field(enc_text, "–í–∏–¥ –æ–±—Ç—è–∂–µ–Ω–Ω—è")
                
                if enc_type or enc_basis:
                    results.append({
                        "–í–∏–¥ –æ–±—Ç—è–∂–µ–Ω–Ω—è": enc_type,
                        "–ü—ñ–¥—Å—Ç–∞–≤–∞ –≤–Ω–µ—Å–µ–Ω–Ω—è –∑–∞–ø–∏—Å—É": enc_basis
                    })

            # --- –û—Å–Ω–æ–≤–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã ---
            section_a_pattern = r"–ê–∫—Ç—É–∞–ª—å–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –æ–±‚Äô—î–∫—Ç —Ä–µ—á–æ–≤–∏—Ö –ø—Ä–∞–≤"
            section_b_pattern = r"–ê–∫—Ç—É–∞–ª—å–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ —Ä–µ—á–æ–≤–µ –ø—Ä–∞–≤–æ"

            a_matches = list(re.finditer(section_a_pattern, block))
            b_matches = list(re.finditer(section_b_pattern, block))

            for i, a_match in enumerate(a_matches):
                current_a_start = a_match.end()
                next_a_match = a_matches[i+1] if (i + 1) < len(a_matches) else None
                
                relevant_b_match = None
                for b_match in b_matches:
                    if b_match.start() > a_match.start():
                        relevant_b_match = b_match
                        break
                
                section_a_end = len(block)
                if relevant_b_match:
                    section_a_end = relevant_b_match.start()
                elif next_a_match:
                    section_a_end = next_a_match.start()
                
                section_a_text = block[current_a_start:section_a_end]

                if "–†–µ—î—Å—Ç—Ä–∞—Ü—ñ–π–Ω–∏–π –Ω–æ–º–µ—Ä –æ–±‚Äô—î–∫—Ç–∞" not in section_a_text:
                    continue

                obj_type = extract_field(section_a_text, "–¢–∏–ø –æ–±‚Äô—î–∫—Ç–∞")
                if not obj_type:
                    continue

                obj_data = {}

                if "–∑–µ–º–µ–ª—å–Ω–∞" in obj_type.lower():
                    cad_num = extract_field(section_a_text, "–ö–∞–¥–∞—Å—Ç—Ä–æ–≤–∏–π –Ω–æ–º–µ—Ä")
                    obj_desc = extract_field(section_a_text, "–û–ø–∏—Å –æ–±‚Äô—î–∫—Ç–∞")
                    obj_data = {
                        "–¢–∏–ø –æ–±‚Äô—î–∫—Ç–∞": obj_type,
                        "–ö–∞–¥–∞—Å—Ç—Ä–æ–≤–∏–π –Ω–æ–º–µ—Ä": cad_num,
                        "–û–ø–∏—Å –æ–±‚Äô—î–∫—Ç–∞": obj_desc
                    }
                    
                    if relevant_b_match:
                        b_start = relevant_b_match.end()
                        b_end = len(block)
                        if next_a_match:
                            b_end = next_a_match.start()
                        section_b_text = block[b_start:b_end]
                        
                        # –ò—â–µ–º "–†–æ–∑–º—ñ—Ä —á–∞—Å—Ç–∫–∏:" –∏ "–î–∞—Ç–∞, —á–∞—Å –¥–µ—Ä–∂–∞–≤–Ω–æ—ó —Ä–µ—î—Å—Ç—Ä–∞—Ü—ñ—ó:" –≤ —Ç–æ–º –∂–µ —Ä–∞–∑–¥–µ–ª–µ
                        share = extract_field(section_b_text, "–†–æ–∑–º—ñ—Ä —á–∞—Å—Ç–∫–∏")
                        if share and share != "1/1":
                            obj_data["–†–æ–∑–º—ñ—Ä —á–∞—Å—Ç–∫–∏"] = share
                        
                        # –ò—â–µ–º "–î–∞—Ç–∞, —á–∞—Å –¥–µ—Ä–∂–∞–≤–Ω–æ—ó —Ä–µ—î—Å—Ç—Ä–∞—Ü—ñ—ó:" –≤ —Ç–æ–º –∂–µ —Ä–∞–∑–¥–µ–ª–µ
                        registration_date = extract_field(section_b_text, "–î–∞—Ç–∞, —á–∞—Å –¥–µ—Ä–∂–∞–≤–Ω–æ—ó —Ä–µ—î—Å—Ç—Ä–∞—Ü—ñ—ó")
                        if registration_date:
                            obj_data["–î–∞—Ç–∞, —á–∞—Å –¥–µ—Ä–∂–∞–≤–Ω–æ—ó —Ä–µ—î—Å—Ç—Ä–∞—Ü—ñ—ó"] = registration_date
                else:
                    address = extract_field(section_a_text, "–ê–¥—Ä–µ—Å–∞")
                    obj_desc = extract_field(section_a_text, "–û–ø–∏—Å –æ–±‚Äô—î–∫—Ç–∞")
                    obj_data = {
                        "–¢–∏–ø –æ–±‚Äô—î–∫—Ç–∞": obj_type,
                        "–û–ø–∏—Å –æ–±‚Äô—î–∫—Ç–∞": obj_desc,
                        "–ê–¥—Ä–µ—Å–∞": address
                    }

                    if relevant_b_match:
                        b_start = relevant_b_match.end()
                        b_end = len(block)
                        if next_a_match:
                            b_end = next_a_match.start()
                        section_b_text = block[b_start:b_end]
                        share = extract_field(section_b_text, "–†–æ–∑–º—ñ—Ä —á–∞—Å—Ç–∫–∏")
                        if share and share != "1/1":
                            obj_data["–†–æ–∑–º—ñ—Ä —á–∞—Å—Ç–∫–∏"] = share
                        
                        # –ò—â–µ–º "–î–∞—Ç–∞, —á–∞—Å –¥–µ—Ä–∂–∞–≤–Ω–æ—ó —Ä–µ—î—Å—Ç—Ä–∞—Ü—ñ—ó:" –≤ —Ç–æ–º –∂–µ —Ä–∞–∑–¥–µ–ª–µ
                        registration_date = extract_field(section_b_text, "–î–∞—Ç–∞, —á–∞—Å –¥–µ—Ä–∂–∞–≤–Ω–æ—ó —Ä–µ—î—Å—Ç—Ä–∞—Ü—ñ—ó")
                        if registration_date:
                            obj_data["–î–∞—Ç–∞, —á–∞—Å –¥–µ—Ä–∂–∞–≤–Ω–æ—ó —Ä–µ—î—Å—Ç—Ä–∞—Ü—ñ—ó"] = registration_date

                if obj_data:
                    results.append(obj_data)

        if not results:
            return "–ù–µ–º–∞—î –∑–∞—Ä–µ—î—Å—Ç—Ä–æ–≤–∞–Ω–æ—ó –Ω–µ—Ä—É—Ö–æ–º–æ—Å—Ç—ñ"

        return results

    except Exception as e:
        return f"–ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ —Ñ–∞–π–ª—É: {str(e)}"

def format_output(all_data):
    output_lines = []
    
    # enumerate –¥–∞–µ—Ç —Å–∫–≤–æ–∑–Ω—É—é –Ω—É–º–µ—Ä–∞—Ü–∏—é
    for i, item in enumerate(all_data, 1):
        if isinstance(item, str):
            output_lines.append(item)
        else:
            for key, value in item.items():
                if value:
                    output_lines.append(f"{key}: {value}")
        
        # –î–≤–∞ –ø—É—Å—Ç—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–∞ —Å–ø–∏—Å–∫–∞ —Å–æ–∑–¥–∞–¥—É—Ç –¥–≤–∞ <br> (–¥–≤–æ–π–Ω–æ–π –æ—Ç—Å—Ç—É–ø)
        output_lines.append("") 
            
    # –°–æ–µ–¥–∏–Ω—è–µ–º —á–µ—Ä–µ–∑ <br> –≤–º–µ—Å—Ç–æ \n –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥–∞ HTML –≤ Streamlit
    return "<br>".join(output_lines)

# --- –ò–ù–¢–ï–†–§–ï–ô–° STREAMLIT ---

st.title("üìÑ –ü–∞—Ä—Å–µ—Ä –≤–∏–ø–∏—Å–æ–∫ –∑ –†–µ—î—Å—Ç—Ä—É –ù–µ—Ä—É—Ö–æ–º–æ—Å—Ç—ñ")
st.write("–ó–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ –æ–¥–∏–Ω –∞–±–æ –∫—ñ–ª—å–∫–∞ PDF-—Ñ–∞–π–ª—ñ–≤ –¥–ª—è –æ–±—Ä–æ–±–∫–∏.")

uploaded_files = st.file_uploader(
    "–í–∏–±–µ—Ä—ñ—Ç—å PDF —Ñ–∞–π–ª–∏", 
    type="pdf", 
    accept_multiple_files=True
)

if st.button("–û–±—Ä–æ–±–∏—Ç–∏ —Ñ–∞–π–ª–∏"):
    if not uploaded_files:
        st.warning("–ë—É–¥—å –ª–∞—Å–∫–∞, –∑–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ —Ö–æ—á–∞ –± –æ–¥–∏–Ω —Ñ–∞–π–ª.")
    else:
        global_results = []
        progress_bar = st.progress(0)
        
        for idx, file in enumerate(uploaded_files):
            result = parse_pdf_file(file)
            
            if isinstance(result, list):
                global_results.extend(result)
            else:
                global_results.append(result)
            
            progress_bar.progress((idx + 1) / len(uploaded_files))
        
        if not global_results:
            formatted_text = "–ù–µ–º–∞—î –¥–∞–Ω–∏—Ö –¥–ª—è –≤—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è."
        else:
            formatted_text = format_output(global_results)
        
        st.markdown("### –†–µ–∑—É–ª—å—Ç–∞—Ç:")
        st.markdown(f'<div class="result-container">{formatted_text}</div>', unsafe_allow_html=True)
        
        # –î–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—ã–µ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
        download_text = formatted_text.replace("<br>", "\n").replace("**", "")
        st.download_button(
            label="–ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —è–∫ .txt",
            data=download_text,
            file_name="result.txt",
            mime="text/plain"
        )